name: redeploy

on:
  push:
    branches: [ main ]
    paths:
      - 'ansible/files/**'
      - 'ansible/roles/**'
      - 'ansible/site.yml'
      - 'docker-compose.yml'
      - 'app/**'
      - '.github/workflows/redeploy.yml'
  workflow_dispatch:
  workflow_run:
    workflows: ["infra"]   # name of your Terraform workflow file (its 'name:')
    types: [completed]

permissions:
  id-token: write
  contents: read

concurrency:
  group: redeploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  redeploy:
    # only run after infra if it succeeded; otherwise still run for normal push/dispatch
    if: github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success'
    runs-on: ubuntu-latest
    env:
      ANSIBLE_INVENTORY_ENABLED: amazon.aws.aws_ec2

    defaults:
      run:
        working-directory: ansible

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}   # ROLE ARN, not provider ARN
          aws-region: us-east-1

      - name: Install Ansible + deps
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install "ansible>=9" boto3 botocore
          ansible-galaxy collection install amazon.aws community.docker

      - name: Write SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/ci_key
          chmod 600 ~/.ssh/ci_key

      - name: Allow runner IP to SSH
        run: |
          set -e
          RUNNER_IP="$(curl -s https://checkip.amazonaws.com)/32"
          echo "Runner public IP: $RUNNER_IP"

          # Find the SG attached to your instance(s)
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=jada-vm" "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].InstanceId" --output text)

          SG_ID=$(aws ec2 describe-instances --instance-ids "$INSTANCE_ID" \
            --query "Reservations[0].Instances[0].SecurityGroups[0].GroupId" --output text)

          echo "Instance: $INSTANCE_ID  SG: $SG_ID"

          # Add the ingress (ignore if it exists)
          aws ec2 authorize-security-group-ingress \
            --group-id "$SG_ID" --protocol tcp --port 22 --cidr "$RUNNER_IP" || true

          echo "SSH allowed from $RUNNER_IP on $SG_ID"
        shell: bash


      - name: Check dynamic inventory
        run: ansible-inventory -i inv_aws_ec2.yml --graph -vvv

      - name: Sync files
        run: |
          ansible all -i inv_aws_ec2.yml -b -m copy \
            -a "src=files/gatus-config.yaml dest=/opt/apps/gatus-config.yaml mode=0644" \
            -e ansible_user=ubuntu -e ansible_ssh_private_key_file=~/.ssh/ci_key
          # If compose is in repo root, also copy it:
          # ansible all -i inv_aws_ec2.yml -b -m copy \
          #   -a "src=../docker-compose.yml dest=/opt/apps/docker-compose.yml mode=0644" \
          #   -e ansible_user=ubuntu -e ansible_ssh_private_key_file=~/.ssh/ci_key

      - name: Pull & restart stack
        run: |
          ansible all -i inv_aws_ec2.yml -b -m shell \
            -a 'cd /opt/apps && docker compose pull && docker compose up -d --remove-orphans' \
            -e ansible_user=ubuntu -e ansible_ssh_private_key_file=~/.ssh/ci_key

      - name: Verify Gatus config on server (first 120 lines)
        run: |
          ansible all -i inv_aws_ec2.yml -b -m shell \
            -a "sed -n '1,120p' /opt/apps/gatus-config.yaml" \
            -e ansible_user=ubuntu -e ansible_ssh_private_key_file=~/.ssh/ci_key